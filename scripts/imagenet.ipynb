{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981492c9-ab8b-4119-a257-3796f4a8dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "# from timm.models import resnet50 as Network\n",
    "from torchvision.models import resnet50 as Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad373dac-afd9-4b33-8188-00499911ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7fce413-77b4-4207-849c-9091f8ba9441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = Network(pretrained=True).to(device)\n",
    "# model = torch.nn.DataParallel(model.to(device))\n",
    "\n",
    "# path = '../logs/train_20210709120956/checkpoint.pth.tar'\n",
    "path = '/root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth'\n",
    "# x = torch.load(path)['model_state_dict']\n",
    "x = torch.load(path)\n",
    "model.load_state_dict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aabd27-136c-477f-9689-87cea264c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for key in x:\n",
    "    new_key = 'backbone.model.' + key[7:]\n",
    "    new_state_dict[new_key] = x[key]\n",
    "torch.save(new_state_dict, '../logs/imagenet_init_resnet50.pth.tar')\n",
    "print(new_state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ccc82e7-27a8-4bf6-8c44-b8ad1adac215",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], \n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a44438-f9c3-46ab-bfda-a761c9b3b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageNet\n",
    "# from efficient_net_v2.train import get_transforms\n",
    "\n",
    "dataset = ImageNet(\n",
    "    root='/workspace/Downloads/datasets/imagenet/', split='val', transform=transform\n",
    ")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bbee5-c345-46da-b4a0-788c4a3ec716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 0.22004 |  Cum Acc 1.000:  22%|██▏       | 11001/50000 [04:23<14:50, 43.79it/s]"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "\n",
    "with tqdm.tqdm(total=len(dataset)) as pbar:\n",
    "    for i, (im, target) in enumerate(dataset):\n",
    "        \n",
    "        im, target = dataset.__getitem__(100)\n",
    "        # plt.imshow(im.cpu().numpy().transpose(1, 2, 0))\n",
    "        # plt.show()\n",
    "        \n",
    "        im = im.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            r = model(im)\n",
    "        r = torch.nn.Softmax(dim=1)(r,)\n",
    "        r = torch.argmax(r).cpu().numpy()\n",
    "        \n",
    "        # print([r, target])\n",
    "        \n",
    "        if r == target:\n",
    "            correct += 1\n",
    "\n",
    "        pbar.set_description(\n",
    "            desc='Acc %3.5f |  Cum Acc %3.3f' % ((correct / len(dataset)), (correct / (i + 1))))\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # if i == 10:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225460b-5be9-4f80-9f49-7fa1a162aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_square(data):\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = (((0, n ** 2 - data.shape[0]),\n",
    "               (0, 1), (0, 1))                 # add some space between filters\n",
    "               + ((0, 0),) * (data.ndim - 3))  # don't pad the last dimension (if there is one)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=1)  # pad with ones (white)\n",
    "    \n",
    "    # tile the filters into an image\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    \n",
    "    plt.imshow(data); \n",
    "    plt.axis('off');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5105b7-5f68-4af2-87f7-c253e1b9f557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, inp, outp):\n",
    "        activation[name] = outp.detach().cpu().numpy()\n",
    "    return hook\n",
    "\n",
    "\n",
    "i = 3\n",
    "hk1 = model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "hk2 = model.layer2[2].conv1.register_forward_hook(get_activation('conv2'))\n",
    "\n",
    "r = model(im)\n",
    "\n",
    "hk1.remove()\n",
    "hk2.remove()\n",
    "\n",
    "# feature_maps = activation['conv1'].squeeze()\n",
    "vis_square(activation['conv1'].squeeze())\n",
    "vis_square(activation['conv2'].squeeze())#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
